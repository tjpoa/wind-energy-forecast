{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f5304c",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520626a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc28c909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f60695b",
   "metadata": {},
   "source": [
    "## Tratar Valores Ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffbfcb",
   "metadata": {},
   "source": [
    "### FF_MED.csv\n",
    "\n",
    "Quando a percentagem de valores ausentes for superior a 30% em cada estação, usamos interpolação linear; nas restantes utilizámos a mediana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d991f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo das colunas com valores ausentes:\n",
      "         Total Ausentes  Percentual (%)\n",
      "ANO                   0            0.00\n",
      "MES                   0            0.00\n",
      "DIA                   0            0.00\n",
      "1200551            1981           49.32\n",
      "1210622            1525           37.96\n",
      "1200567              14            0.35\n",
      "1200575              57            1.42\n",
      "1200545             283            7.05\n",
      "1210702             663           16.50\n",
      "1200560              83            2.07\n",
      "1210683             190            4.73\n",
      "1200548              57            1.42\n",
      "1200570               1            0.02\n",
      "1210718             191            4.75\n",
      "1210734              52            1.29\n",
      "1200571             226            5.63\n",
      "1200579              32            0.80\n",
      "1210770             192            4.78\n",
      "1200558              28            0.70\n",
      "1200562             471           11.73\n",
      "1200554             352            8.76\n"
     ]
    }
   ],
   "source": [
    "# Caminho para o dataset\n",
    "dataset_path = os.path.join('data', 'raw', 'Dados_diarios_T_Vento_Prec_capitaisDistrito_2013 a 2023.xlsx')\n",
    "\n",
    "# Importando a folha 'FF_MED', tratando -990 como ausente\n",
    "df = pd.read_excel(dataset_path, sheet_name='FF_MED', na_values=-990)\n",
    "\n",
    "# Resumo dos valores ausentes\n",
    "missing_data = pd.DataFrame({\n",
    "    'Total Ausentes': df.isnull().sum(),\n",
    "    'Percentual (%)': (df.isnull().mean() * 100).round(2)\n",
    "})\n",
    "\n",
    "print(\"\\nResumo das colunas com valores ausentes:\")\n",
    "print(missing_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64d26c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo dos valores ausentes após tratamento:\n",
      "ANO        0\n",
      "MES        0\n",
      "DIA        0\n",
      "1200551    0\n",
      "1210622    0\n",
      "1200567    0\n",
      "1200575    0\n",
      "1200545    0\n",
      "1210702    0\n",
      "1200560    0\n",
      "1210683    0\n",
      "1200548    0\n",
      "1200570    0\n",
      "1210718    0\n",
      "1210734    0\n",
      "1200571    0\n",
      "1200579    0\n",
      "1210770    0\n",
      "1200558    0\n",
      "1200562    0\n",
      "1200554    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_percent = (df.isnull().mean() * 100)\n",
    "\n",
    "# Fazendo uma cópia do dataframe original para tratamento\n",
    "df_treated = df.copy()\n",
    "\n",
    "# Tratamento:\n",
    "for col in df.columns:\n",
    "    if missing_percent[col] > 30:\n",
    "        # Se mais de 30% de ausentes → interpolar\n",
    "        df_treated[col] = df_treated[col].interpolate(method='linear', limit_direction='both')\n",
    "        # Preencher o que ainda sobrou (bordas) com a mediana\n",
    "        mediana = df_treated[col].median()\n",
    "        df_treated[col] = df_treated[col].fillna(mediana)\n",
    "    elif missing_percent[col] < 30:\n",
    "        # Se menos de 5% de ausentes → preencher com mediana\n",
    "        mediana = df_treated[col].median()\n",
    "        df_treated[col] = df_treated[col].fillna(mediana)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Resultado final\n",
    "print(\"\\nResumo dos valores ausentes após tratamento:\")\n",
    "print(df_treated.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2039c927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvando o dataset tratado em CSV\n",
    "df_treated.to_csv('data/processed/FF_MED_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d238fc",
   "metadata": {},
   "source": [
    "### TT_MED.csv\n",
    "Substitui os valores ausentes pela temperatura média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db1a1e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo dos valores ausentes antes do tratamento na folha TT_MED:\n",
      "ANO          0\n",
      "MES          0\n",
      "DIA          0\n",
      "1200551    288\n",
      "1210622    240\n",
      "1200567     14\n",
      "1200575     49\n",
      "1200545    512\n",
      "1210702     98\n",
      "1200560     32\n",
      "1210683    198\n",
      "1200548     94\n",
      "1200570      5\n",
      "1210718    343\n",
      "1210734     48\n",
      "1200571    332\n",
      "1200579     51\n",
      "1210770    297\n",
      "1200558     30\n",
      "1200562    594\n",
      "1200554     31\n",
      "dtype: int64\n",
      "\n",
      "Resumo dos valores ausentes após o tratamento na folha TT_MED:\n",
      "ANO        0\n",
      "MES        0\n",
      "DIA        0\n",
      "1200551    0\n",
      "1210622    0\n",
      "1200567    0\n",
      "1200575    0\n",
      "1200545    0\n",
      "1210702    0\n",
      "1200560    0\n",
      "1210683    0\n",
      "1200548    0\n",
      "1200570    0\n",
      "1210718    0\n",
      "1210734    0\n",
      "1200571    0\n",
      "1200579    0\n",
      "1210770    0\n",
      "1200558    0\n",
      "1200562    0\n",
      "1200554    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho para o dataset\n",
    "dataset_path = os.path.join('data', 'raw', 'Dados_diarios_T_Vento_Prec_capitaisDistrito_2013 a 2023.xlsx')\n",
    "\n",
    "# Importando a folha 'TT_MED', tratando -990 como ausente\n",
    "df_ttmed = pd.read_excel(dataset_path, sheet_name='T_MED', na_values=-990)\n",
    "\n",
    "# Verificando se existem valores ausentes antes de qualquer tratamento\n",
    "print(\"\\nResumo dos valores ausentes antes do tratamento na folha TT_MED:\")\n",
    "print(df_ttmed.isnull().sum())\n",
    "\n",
    "# Se houver valores ausentes, vamos prosseguir com o tratamento:\n",
    "if df_ttmed.isnull().sum().sum() > 0:\n",
    "    # Calculando a média global (média de todos os valores numéricos do dataframe)\n",
    "    media_global = df_ttmed.select_dtypes(include=['float64', 'int64']).stack().mean()\n",
    "\n",
    "    # Preenchendo valores ausentes com a média global\n",
    "    df_ttmed.fillna(media_global, inplace=True)\n",
    "\n",
    "    # Resultado final após o tratamento\n",
    "    print(\"\\nResumo dos valores ausentes após o tratamento na folha TT_MED:\")\n",
    "    print(df_ttmed.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "    # Salvando o dataset tratado em Excel (opcional)\n",
    "    df_ttmed.to_csv('data/processed/T_MED_processed.csv', index=False)\n",
    "else:\n",
    "    print(\"\\nNão há valores ausentes na folha TT_MED.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b34db4",
   "metadata": {},
   "source": [
    "### DD_MED.csv\n",
    "Substitui-se os valores ausentes pela mediana circular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8a1df9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resumo dos valores ausentes antes do tratamento na folha DD_MED:\n",
      "ANO           0\n",
      "MES           0\n",
      "DIA           0\n",
      "1200551    2540\n",
      "1210622    1090\n",
      "1200567      36\n",
      "1200575      47\n",
      "1200545     617\n",
      "1210702     665\n",
      "1200560      85\n",
      "1210683     191\n",
      "1200548      63\n",
      "1200570       1\n",
      "1210718     207\n",
      "1210734      62\n",
      "1200571    1052\n",
      "1200579      36\n",
      "1210770     192\n",
      "1200558      36\n",
      "1200562     287\n",
      "1200554    1026\n",
      "dtype: int64\n",
      "\n",
      "Resumo dos valores ausentes após o tratamento na folha DD_MED:\n",
      "ANO        0\n",
      "MES        0\n",
      "DIA        0\n",
      "1200551    0\n",
      "1210622    0\n",
      "1200567    0\n",
      "1200575    0\n",
      "1200545    0\n",
      "1210702    0\n",
      "1200560    0\n",
      "1210683    0\n",
      "1200548    0\n",
      "1200570    0\n",
      "1210718    0\n",
      "1210734    0\n",
      "1200571    0\n",
      "1200579    0\n",
      "1210770    0\n",
      "1200558    0\n",
      "1200562    0\n",
      "1200554    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular a mediana circular (em graus)\n",
    "def circular_median(values):\n",
    "    # Converte os valores para radianos\n",
    "    radians = np.deg2rad(values)\n",
    "    # Calcula o seno e cosseno da média\n",
    "    median_radians = np.arctan2(np.mean(np.sin(radians)), np.mean(np.cos(radians)))\n",
    "    # Converte de volta para graus\n",
    "    return np.rad2deg(median_radians) % 360\n",
    "\n",
    "# Caminho para o dataset\n",
    "dataset_path = os.path.join('data', 'raw', 'Dados_diarios_T_Vento_Prec_capitaisDistrito_2013 a 2023.xlsx')\n",
    "\n",
    "# Importando a folha 'DD_MED', tratando -990 como ausente\n",
    "df_ddmed = pd.read_excel(dataset_path, sheet_name='DD_MED', na_values=-990)\n",
    "\n",
    "# Verificando se existem valores ausentes antes de qualquer tratamento\n",
    "print(\"\\nResumo dos valores ausentes antes do tratamento na folha DD_MED:\")\n",
    "print(df_ddmed.isnull().sum())\n",
    "\n",
    "# Se houver valores ausentes, vamos prosseguir com o tratamento:\n",
    "if df_ddmed.isnull().sum().sum() > 0:\n",
    "    # Calculando a mediana circular\n",
    "    mediana_circular = circular_median(df_ddmed.select_dtypes(include=['float64', 'int64']).stack())\n",
    "\n",
    "    # Preenchendo valores ausentes com a mediana circular\n",
    "    df_ddmed.fillna(mediana_circular, inplace=True)\n",
    "\n",
    "    # Resultado final após o tratamento\n",
    "    print(\"\\nResumo dos valores ausentes após o tratamento na folha DD_MED:\")\n",
    "    print(df_ddmed.isnull().sum())\n",
    "\n",
    "    # Salvando o dataset tratado em Excel (opcional)\n",
    "    df_ddmed.to_csv('data/processed/DD_MED_processed.csv', index=False)\n",
    "else:\n",
    "    print(\"\\nNão há valores ausentes na folha DD_MED.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267171f2",
   "metadata": {},
   "source": [
    "### Repartição da Produção_200100101_20250424.csv\n",
    "\n",
    "Não tem valores ausentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4dffafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/raw/Repartição da Produção_200100101_20250424.csv\"\n",
    "df = pd.read_csv(file_path, encoding='utf-8', sep=';', skiprows=2)\n",
    "missing_values = df.isna().sum()\n",
    "print(missing_values[missing_values > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baabab47",
   "metadata": {},
   "source": [
    "## Agregação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc2c95e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Data  Intensidade_Media  Direcao_Media  Temperatura_Media    Eólica\n",
      "0 2013-01-01           1.629318     327.262439           9.488889   89358.2\n",
      "1 2013-01-02           1.564218      31.852420           8.683333  118865.5\n",
      "2 2013-01-03           2.676138      79.706195           9.277778  232257.7\n",
      "3 2013-01-04           1.996991      88.710336           8.761111  149543.7\n",
      "4 2013-01-05           1.045090      83.465882           8.600000   23830.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def carregar_dados_eolica(path_eolica: str) -> pd.DataFrame:\n",
    "    \"\"\"Carrega produção eólica, mantendo apenas Data e Hora e Eólica.\"\"\"\n",
    "    df = pd.read_csv(path_eolica, sep=';', skiprows=2, parse_dates=['Data e Hora'])\n",
    "    df.columns = df.columns.str.strip()\n",
    "    df = df[['Data e Hora', 'Eólica']]\n",
    "    df.set_index('Data e Hora', inplace=True)\n",
    "    df_diario = df.resample('D').sum().reset_index()\n",
    "    df_diario.rename(columns={'Data e Hora': 'Data'}, inplace=True)\n",
    "    return df_diario\n",
    "\n",
    "def carregar_dd_ff(dd_path: str, ff_path: str) -> pd.DataFrame:\n",
    "    dd = pd.read_csv(dd_path)\n",
    "    ff = pd.read_csv(ff_path)\n",
    "\n",
    "    # Renomear colunas para compatibilidade com pd.to_datetime\n",
    "    dd = dd.rename(columns={'ANO': 'year', 'MES': 'month', 'DIA': 'day'})\n",
    "    ff = ff.rename(columns={'ANO': 'year', 'MES': 'month', 'DIA': 'day'})\n",
    "\n",
    "    # Criar coluna de data\n",
    "    dd['Data'] = pd.to_datetime(dd[['year', 'month', 'day']])\n",
    "    ff['Data'] = pd.to_datetime(ff[['year', 'month', 'day']])\n",
    "\n",
    "    # Estações são colunas com nomes numéricos\n",
    "    estacoes = [col for col in dd.columns if col.isdigit()]\n",
    "\n",
    "    dd_rad = np.deg2rad(dd[estacoes])\n",
    "    x = ff[estacoes] * np.cos(dd_rad)\n",
    "    y = ff[estacoes] * np.sin(dd_rad)\n",
    "\n",
    "    x_medio = x.mean(axis=1)\n",
    "    y_medio = y.mean(axis=1)\n",
    "\n",
    "    intensidade_media = np.sqrt(x_medio**2 + y_medio**2)\n",
    "    direcao_media = (np.rad2deg(np.arctan2(y_medio, x_medio))) % 360\n",
    "\n",
    "    df_nacional = pd.DataFrame({\n",
    "        'Data': dd['Data'],\n",
    "        'Intensidade_Media': intensidade_media,\n",
    "        'Direcao_Media': direcao_media\n",
    "    })\n",
    "    return df_nacional\n",
    "\n",
    "def carregar_temperatura(temp_path: str) -> pd.DataFrame:\n",
    "    temp = pd.read_csv(temp_path)\n",
    "\n",
    "    # Renomear colunas\n",
    "    temp = temp.rename(columns={'ANO': 'year', 'MES': 'month', 'DIA': 'day'})\n",
    "    temp['Data'] = pd.to_datetime(temp[['year', 'month', 'day']])\n",
    "\n",
    "    estacoes = [col for col in temp.columns if col.isdigit()]\n",
    "    temp_media = temp[estacoes].mean(axis=1)\n",
    "\n",
    "    df_temp = pd.DataFrame({\n",
    "        'Data': temp['Data'],\n",
    "        'Temperatura_Media': temp_media\n",
    "    })\n",
    "    return df_temp\n",
    "\n",
    "\n",
    "def main():\n",
    "    path_eolica = 'data/raw/Repartição da Produção_200100101_20250424.csv'\n",
    "    path_dd = 'data/processed/DD_MED_processed.csv'\n",
    "    path_ff = 'data/processed/FF_MED_processed.csv'\n",
    "    path_temp = 'data/processed/T_MED_processed.csv'\n",
    "    pasta_saida = 'data/processed/'\n",
    "\n",
    "    # Carregar datasets\n",
    "    df_eolica = carregar_dados_eolica(path_eolica)\n",
    "    df_vento = carregar_dd_ff(path_dd, path_ff)\n",
    "    df_temp = carregar_temperatura(path_temp)\n",
    "\n",
    "    # Juntar meteorologia (vento + temperatura)\n",
    "    df_meteo = pd.merge(df_vento, df_temp, on='Data')\n",
    "\n",
    "    # Juntar meteorologia + produção eólica\n",
    "    df_final = pd.merge(df_meteo, df_eolica, on='Data', how='left')\n",
    "\n",
    "    Path(pasta_saida).mkdir(parents=True, exist_ok=True)\n",
    "    df_final.to_csv(Path(pasta_saida) / 'meteorologia_eolica.csv', index=False, sep=';')\n",
    "\n",
    "    print(df_final.head())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
